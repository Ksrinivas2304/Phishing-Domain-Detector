{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66336eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Have_IP</th>\n",
       "      <th>Have_At</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>URL_Depth</th>\n",
       "      <th>Redirection</th>\n",
       "      <th>https_Domain</th>\n",
       "      <th>TinyURL</th>\n",
       "      <th>Prefix/Suffix</th>\n",
       "      <th>DNS_Record</th>\n",
       "      <th>Web_Traffic</th>\n",
       "      <th>Domain_Age</th>\n",
       "      <th>Domain_End</th>\n",
       "      <th>whois</th>\n",
       "      <th>iFrame</th>\n",
       "      <th>Mouse_Over</th>\n",
       "      <th>Right_Click</th>\n",
       "      <th>Web_Forwards</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1337x.to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1337x.to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337x.to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337x.to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337x.to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Domain  Have_IP  Have_At  URL_Length  URL_Depth  Redirection  \\\n",
       "0  1337x.to        0        0           1          3            0   \n",
       "1  1337x.to        0        0           1          3            0   \n",
       "2  1337x.to        0        0           1          3            0   \n",
       "3  1337x.to        0        0           1          3            0   \n",
       "4  1337x.to        0        0           1          3            0   \n",
       "\n",
       "   https_Domain  TinyURL  Prefix/Suffix  DNS_Record  Web_Traffic  Domain_Age  \\\n",
       "0             0        0              0           0            1           1   \n",
       "1             0        0              0           0            1           1   \n",
       "2             0        0              0           0            1           1   \n",
       "3             0        0              0           0            1           1   \n",
       "4             0        0              0           0            1           1   \n",
       "\n",
       "   Domain_End  whois  iFrame  Mouse_Over  Right_Click  Web_Forwards  Label  \n",
       "0           1      0       1           1            0           0.0      0  \n",
       "1           1      0       1           1            0           0.0      0  \n",
       "2           1      0       1           1            0           0.0      0  \n",
       "3           1      0       1           1            0           0.0      0  \n",
       "4           1      0       1           1            0           0.0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "urldata=pd.read_csv('data.csv')\n",
    "urldata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f580c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hp\\anaconda3\\new folder\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\new folder\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\new folder\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7d6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = urldata[['Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection',\n",
    "                 'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', 'Domain_Age', 'Domain_End', 'whois', 'iFrame',\n",
    "                 'Mouse_Over', 'Right_Click', 'Web_Forwards']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd05f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = urldata['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1697460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    objective='binary:logistic'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81329a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3677d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c88bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560439560439561\n",
      "Precision: 0.9775280898876404\n",
      "Recall: 0.9354838709677419\n",
      "F1-score: 0.956043956043956\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d3b84f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-whois in c:\\users\\hp\\anaconda3\\new folder\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\anaconda3\\new folder\\lib\\site-packages (from python-whois) (0.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed2a9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322fc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_whois_data(url):\n",
    "    try:\n",
    "        whois_data = whois.whois(url)\n",
    "        return whois_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting WHOIS data for {url}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f982d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_phishing_probability(whois_data):\n",
    "    if whois_data is None:\n",
    "        return None\n",
    "\n",
    "    if 'creation_date' in whois_data:\n",
    "        creation_date = whois_data['creation_date']\n",
    "        if isinstance(creation_date, list) and len(creation_date) > 0:\n",
    "\n",
    "            today = pd.Timestamp.today()\n",
    "            if (today - creation_date[0]).days <= 365:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b306eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse,urlencode\n",
    "import ipaddress\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89806201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDomain(url):\n",
    "  parsed_url = urlparse(url)\n",
    "\n",
    "    # Extract the netloc (domain) from the parsed URL\n",
    "  domain_name = parsed_url.netloc\n",
    "\n",
    "    # Return the domain name\n",
    "  return domain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea00b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip\n",
    "\n",
    "\n",
    "\n",
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1\n",
    "  else:\n",
    "    at = 0\n",
    "  return at\n",
    "\n",
    "\n",
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0\n",
    "  else:\n",
    "    length = 1\n",
    "  return length\n",
    "\n",
    "\n",
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth\n",
    "\n",
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_traffic(url):\n",
    "    try:\n",
    "        url = urllib.parse.quote(url)\n",
    "        rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n",
    "        rank = int(rank)\n",
    "        if rank < 100000:\n",
    "            return 1  # Phishing\n",
    "        else:\n",
    "            return 0  # Legitimate\n",
    "    except (TypeError, urllib.error.URLError) as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "import re\n",
    "def tinyURL(url):\n",
    "  match=re.search(shortening_services,url)\n",
    "  if match:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)\n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End)\n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[|]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1\n",
    "\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response):\n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)\n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b1c0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "\n",
    "def is_phishing_domain(domain):\n",
    "  try:\n",
    "\n",
    "        # Query WHOIS information for the domain\n",
    "    w = whois.whois(domain)\n",
    "    if not w or \"status\" not in w.keys():\n",
    "      return 1  # Phishing\n",
    "    else:\n",
    "      return 0  # Legitimate\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "438c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "\n",
    "def display_whois_data(url):\n",
    "    try:\n",
    "      whois_data = whois.whois(url)\n",
    "      print(\"Domain Name:\", whois_data.domain_name)\n",
    "      print(\"Registrar:\", whois_data.registrar)\n",
    "      print(\"Creation Date:\", whois_data.creation_date)\n",
    "      print(\"Expiration Date:\", whois_data.expiration_date)\n",
    "      print(\"Updated Date:\", whois_data.updated_date)\n",
    "      print(\"Name Servers:\", whois_data.name_servers)\n",
    "        # Add more WHOIS data fields as needed\n",
    "    except Exception as e:\n",
    "      print(f\"Error fetching WHOIS data for {url}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f01687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainexe(url):\n",
    "  features=[]\n",
    "  features.append(getDomain(url))\n",
    "  features.append(havingIP(url))\n",
    "  features.append(haveAtSign(url))\n",
    "  features.append(getLength(url))\n",
    "  features.append(getDepth(url))\n",
    "  features.append(redirection(url))\n",
    "  features.append(httpDomain(url))\n",
    "  features.append(tinyURL(url))\n",
    "  features.append(prefixSuffix(url))\n",
    "\n",
    "  dns = 0\n",
    "  try:\n",
    "    domain_name = whois.whois(urlparse(url).netloc)\n",
    "  except:\n",
    "    dns = 1\n",
    "  features.append(dns)\n",
    "  #features.append(is_phishing_domain(url))\n",
    "  features.append(web_traffic(url))\n",
    "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except:\n",
    "    response = \"\"\n",
    "  features.append(iframe(response))\n",
    "  features.append(mouseOver(response))\n",
    "  features.append(rightClick(response))\n",
    "  features.append(forwarding(response))\n",
    "  whois_data = extract_whois_data(url)\n",
    "  features.append(calculate_phishing_probability(whois_data))\n",
    "\n",
    "  print(features)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd67a98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter url:http://localhost:8888/notebooks/Desktop/MyApp/detection.ipynb\n",
      "An error occurred: <urlopen error [Errno 11001] getaddrinfo failed>\n",
      "['localhost:8888', 0, 0, 1, 4, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n",
      "safe\n",
      "Domain Name: None\n",
      "Registrar: None\n",
      "Creation Date: None\n",
      "Expiration Date: None\n",
      "Updated Date: None\n",
      "Name Servers: None\n"
     ]
    }
   ],
   "source": [
    "url=input(\"enter url:\")\n",
    "train=[]\n",
    "train.append(trainexe(url))\n",
    "feature_names = ['domain','Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection',\n",
    "                 'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', 'Domain_Age', 'Domain_End', 'whois', 'iFrame',\n",
    "                 'Mouse_Over', 'Right_Click', 'Web_Forwards']\n",
    "feature = pd.DataFrame(train, columns= feature_names)\n",
    "X = feature[['domain','Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection',\n",
    "                 'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', 'Domain_Age', 'Domain_End', 'whois', 'iFrame',\n",
    "                 'Mouse_Over', 'Right_Click', 'Web_Forwards']]\n",
    "X = X.drop(\"domain\", axis=1)\n",
    "y_pred = model.predict(X)\n",
    "if(y_pred==0):\n",
    "  print(\"safe\")\n",
    "  display_whois_data(url)\n",
    "else:\n",
    "  print(\"suspisious\")\n",
    "  display_whois_data(url)\n",
    "probability = model.predict_proba(X)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e6d7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "\n",
    "pickle.dump(model, open('model.pkl','wb'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "845d06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "'''model = pickle.load(open('model.pkl','rb'))\n",
    "print(model.predict(X))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c442150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Your Python object (e.g., a trained machine learning model)\n",
    "model = ...  # Replace with your object\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = \"model.pkl\"\n",
    "\n",
    "# Open the file in binary write mode and save the object\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71ec9c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file path of the pickle file\n",
    "file_path = \"model.pkl\"\n",
    "\n",
    "try:\n",
    "    # Open the file in binary read mode and load the object\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "\n",
    "    # Now, loaded_object contains the Python object from the pickle file\n",
    "    print(\"Object loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455e77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2654f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
